{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d240ad3",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "This notebook implements the full experimental pipeline described in the manuscript:\n",
    "\n",
    "**‚ÄúA rigorous statistical benchmark of global neural time-series models for multi-horizon air pollutant forecasting.‚Äù**\n",
    "\n",
    "Its purpose is to:\n",
    "\n",
    "- Define and train the fifteen forecasting models evaluated in the study;\n",
    "- Execute rolling-origin cross-validation (ROCV) across the four forecast horizons (1, 7, 14, and 30 days);\n",
    "- Generate multi-step forecasts for each pollutant and grid cell;\n",
    "- Compute evaluation metrics (MAE, RMSE, sMAPE);\n",
    "- Apply deterministic scaling for numerical stability in neural training;\n",
    "\n",
    "This notebook reproduces all numerical results used in the performance and inferential analyses of the manuscript."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690ca9ba",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acd705b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gustavo.filho\\Documents\\Python\\Masters\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['NIXTLA_ID_AS_COL'] = '1'\n",
    "import glob\n",
    "\n",
    "import optuna\n",
    "import itertools\n",
    "import shutil\n",
    "import time\n",
    "import functools\n",
    "import gc\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "import scipy.stats as stats\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.subplots\n",
    "import plotly.io as pio\n",
    "from graphmodex import plotlymodex\n",
    "pio.renderers.default = 'notebook'\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import joblib\n",
    "import pickle\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e6358f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-16 08:45:46,189\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2026-02-16 08:45:46,654\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "üí° Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](https://pypi.org/project/litlogger/) to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.\n"
     ]
    }
   ],
   "source": [
    "import neuralforecast\n",
    "import mlforecast\n",
    "import statsforecast\n",
    "import utilsforecast\n",
    "import coreforecast\n",
    "\n",
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import (\n",
    "    Naive, SeasonalNaive, \n",
    "    AutoARIMA, AutoCES, AutoETS, AutoTheta,\n",
    ")\n",
    "\n",
    "from mlforecast import MLForecast\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from mlforecast.lag_transforms import ExpandingMean, RollingMean\n",
    "from mlforecast.target_transforms import Differences\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import (\n",
    "    NBEATS, NHITS,\n",
    "    GRU, Informer, LSTM\n",
    ")\n",
    "from neuralforecast.losses.pytorch import MSE, SMAPE, MAE\n",
    "\n",
    "from mlforecast.utils import PredictionIntervals\n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "trainer = Trainer(\n",
    "    max_steps=4,\n",
    "    logger=False,\n",
    "    enable_progress_bar=False,\n",
    "    enable_model_summary=False\n",
    ")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"optuna\")\n",
    "\n",
    "\n",
    "# ==================================================\n",
    "# REPRODUCTIBILITY\n",
    "# ==================================================\n",
    "import random\n",
    "import torch\n",
    "\n",
    "SEED = 1\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a68f6cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"overflow encountered in square\",\n",
    "    category=RuntimeWarning,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6b7ed22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_gpu_utilization():\n",
    "    if torch.cuda.is_available():\n",
    "        usage = torch.cuda.memory_reserved() / 1024**3 # GB\n",
    "        total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "        print(f\"GPU usage: {usage:.2f}GB / {total:.2f}GB\")\n",
    "\n",
    "# Call this at the start of your loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0227fb",
   "metadata": {},
   "source": [
    "### Results Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92c42d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "BASE_RESULTS = Path(\"Results/RQ1\")\n",
    "BASE_RESULTS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_results(df, model_family, pollutant, horizon_label):\n",
    "    out_dir = BASE_RESULTS / model_family\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    fname = f\"{pollutant}_{horizon_label}.csv\"\n",
    "    df.to_csv(out_dir / fname, index=False)\n",
    "\n",
    "BASE_DIR_Pilot = Path(\"Results/RQ1/Pilot\")\n",
    "(BASE_DIR_Pilot / \"studies\").mkdir(parents=True, exist_ok=True)\n",
    "(BASE_DIR_Pilot / \"tables\").mkdir(parents=True, exist_ok=True)\n",
    "(BASE_DIR_Pilot / \"meta\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db976d17",
   "metadata": {},
   "source": [
    "## Data & Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55eed7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# DATA\n",
    "# ===============================\n",
    "df = pd.read_parquet(r'..\\Data\\CAMS\\processed\\eac4_era5_2010_2024_brasil_enhanced.parquet')\n",
    "\n",
    "pm10 = (\n",
    "    df\n",
    "    .rename(columns={\n",
    "        'pm10': 'y',\n",
    "        'valid_time': 'ds'        \n",
    "    })\n",
    "    .query('state == \"Paran√°\"')\n",
    "    [['unique_id', 'ds', 'y']]\n",
    ")\n",
    "\n",
    "pm2p5 = (\n",
    "    df\n",
    "    .rename(columns={\n",
    "        'pm2p5': 'y',\n",
    "        'valid_time': 'ds'        \n",
    "    })\n",
    "    .query('state == \"Paran√°\"')\n",
    "    [['unique_id', 'ds', 'y']]\n",
    ")\n",
    "\n",
    "go3 = (\n",
    "    df\n",
    "    .rename(columns={\n",
    "        'go3': 'y',\n",
    "        'valid_time': 'ds'        \n",
    "    })\n",
    "    .query('state == \"Paran√°\"')\n",
    "    [['unique_id', 'ds', 'y']]\n",
    ")\n",
    "\n",
    "no2 = (\n",
    "    df\n",
    "    .rename(columns={\n",
    "        'no2': 'y',\n",
    "        'valid_time': 'ds'        \n",
    "    })\n",
    "    .query('state == \"Paran√°\"')\n",
    "    [['unique_id', 'ds', 'y']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c043a95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# go3.to_parquet(r'.\\Results\\RQ1\\full\\go3.parquet')\n",
    "# pm10.to_parquet(r'.\\Results\\RQ1\\full\\nopm102.parquet')\n",
    "# pm2p5.to_parquet(r'.\\Results\\RQ1\\full\\nopm2p52.parquet')\n",
    "# no2.to_parquet(r'.\\Results\\RQ1\\full\\no2.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2497c7",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25e28388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# PILOT CONFIG\n",
    "# ===============================\n",
    "POLLUTANT_abl = 'pm10'\n",
    "UID_abl = 0\n",
    "\n",
    "steps_per_day = 8\n",
    "horizons = {\n",
    "    '1d': 1 * steps_per_day,\n",
    "    '7d': 7 * steps_per_day,\n",
    "    '14d': 14 * steps_per_day,\n",
    "    '30d': 30 * steps_per_day,\n",
    "}\n",
    "\n",
    "# ===============================\n",
    "# DATA\n",
    "# ===============================\n",
    "df_abl = (\n",
    "    df\n",
    "    .query(\"unique_id == @UID_abl\")\n",
    "    .rename(columns={'pm10': 'y', 'valid_time': 'ds'})\n",
    "    [['unique_id', 'ds', 'y']]\n",
    "    .sort_values('ds')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "005de51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# CONFIG\n",
    "# ===============================\n",
    "steps_per_day = 8\n",
    "two_year_steps = 2 * 365 * steps_per_day\n",
    "target_windows = 30\n",
    "\n",
    "FREQ = '3h'\n",
    "SEASON_LENGTH = 8 \n",
    "\n",
    "pollutants_dict = {\n",
    "        'go3': {\n",
    "            'df': go3,\n",
    "            'scaler': 1e8\n",
    "        },\n",
    "        'no2': {\n",
    "            'df': no2,\n",
    "            'scaler': 1e10\n",
    "        },\n",
    "        'pm10': {\n",
    "            'df': pm10,\n",
    "            'scaler': 1e9\n",
    "        },\n",
    "        'pm2p5': {\n",
    "            'df': pm2p5,\n",
    "            'scaler': 1e9\n",
    "        },\n",
    "    }\n",
    "experiments_dict = {\n",
    "    '1 days': {\n",
    "        'horizon': 8*1,\n",
    "        'step_size': max(8*1, two_year_steps // target_windows),\n",
    "        'windows': target_windows,\n",
    "    },\n",
    "    '7 days': {\n",
    "        'horizon': 8*7,\n",
    "        'step_size': max(8*7, two_year_steps // target_windows),\n",
    "        'windows': target_windows,\n",
    "    },\n",
    "    '14 days': {\n",
    "        'horizon': 8*14,\n",
    "        'step_size': max(8*14, two_year_steps // target_windows),\n",
    "        'windows': target_windows,\n",
    "    },\n",
    "    '30 days': {\n",
    "        'horizon': 8*30,\n",
    "        'step_size': 8*30,\n",
    "        'windows': two_year_steps // (8*30),  # 24\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b805961",
   "metadata": {},
   "source": [
    "## **Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766c7b3f",
   "metadata": {},
   "source": [
    "### Refit Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa30211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# Refit Sensitivity Test Configuration\n",
    "# =========================================================\n",
    "\n",
    "TEST_POLLUTANT = list(pollutants_dict.keys())[0]        # Select first pollutant\n",
    "TEST_HORIZON_LABEL = list(experiments_dict.keys())[2]   # Select third horizon\n",
    "H = experiments_dict[TEST_HORIZON_LABEL]['horizon']\n",
    "WINDOWS = 5                                             # Reduced for computational efficiency\n",
    "STEP_SIZE = experiments_dict[TEST_HORIZON_LABEL]['step_size']\n",
    "\n",
    "refit_comparison = []\n",
    "\n",
    "# =========================================================\n",
    "# Comparative Loop: refit=True vs refit=False\n",
    "# =========================================================\n",
    "for refit_mode in [True, False]:\n",
    "\n",
    "    print(f\"\\nTesting configuration with refit={refit_mode}...\")\n",
    "    \n",
    "    # Simplified model configuration for sensitivity analysis\n",
    "    model = NHITS(\n",
    "        h=H,\n",
    "        input_size=14 * 8,\n",
    "        max_steps=300,\n",
    "        random_seed=SEED,\n",
    "        loss=MAE()\n",
    "    )\n",
    "    \n",
    "    nf = NeuralForecast(models=[model], freq=FREQ)\n",
    "\n",
    "    df_test = pollutants_dict[TEST_POLLUTANT]['df'].copy()\n",
    "\n",
    "    # Deterministic scaling for numerical stability (consistent with main experiment)\n",
    "    df_test['y'] = df_test['y'] * 1e8\n",
    "\n",
    "    # Time tracking\n",
    "    start_t = time.time()\n",
    "    \n",
    "    cv_results = nf.cross_validation(\n",
    "        df=df_test,\n",
    "        h=H,\n",
    "        n_windows=WINDOWS,\n",
    "        step_size=STEP_SIZE,\n",
    "        refit=refit_mode\n",
    "    )\n",
    "\n",
    "    # Rescale forecasts back to physical units\n",
    "    cv_results['y'] = cv_results['y'] * 1e-8\n",
    "    cv_results['NHITS'] = cv_results['NHITS'] * 1e-8\n",
    "    \n",
    "    end_t = time.time()\n",
    "    duration = end_t - start_t\n",
    "    \n",
    "    # Compute global mean absolute error across CV windows\n",
    "    mae_val = np.mean(np.abs(cv_results['y'] - cv_results['NHITS']))\n",
    "    \n",
    "    refit_comparison.append({\n",
    "        'refit': refit_mode,\n",
    "        'MAE': mae_val,\n",
    "        'Time_Sec': duration,\n",
    "        'Time_Per_Window': duration / WINDOWS\n",
    "    })\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Results Analysis\n",
    "# =========================================================\n",
    "comparison_df = pd.DataFrame(refit_comparison)\n",
    "\n",
    "# Percentage change in MAE between configurations\n",
    "comparison_df['MAE_Diff_Pct'] = comparison_df['MAE'].pct_change() * 100\n",
    "\n",
    "# Relative speed-up factor\n",
    "comparison_df['Speedup_Factor'] = (\n",
    "    comparison_df.iloc[0]['Time_Sec'] / comparison_df['Time_Sec']\n",
    ")\n",
    "\n",
    "print(\"\\n=== REFIT TRUE vs FALSE COMPARISON ===\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Logical consistency check\n",
    "mae_diff = abs(\n",
    "    comparison_df.iloc[0]['MAE'] - comparison_df.iloc[1]['MAE']\n",
    ")\n",
    "\n",
    "print(f\"\\nAbsolute MAE difference: {mae_diff:.6f}\")\n",
    "\n",
    "if mae_diff < 0.01:  # Threshold should be interpreted relative to scale\n",
    "    print(\"Conclusion: The error difference is negligible. refit=False is acceptable.\")\n",
    "else:\n",
    "    print(\"Warning: A noticeable error difference was detected. Verify stability assumptions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121388ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# Refit Sensitivity Test Configuration\n",
    "# =========================================================\n",
    "\n",
    "TEST_POLLUTANT = list(pollutants_dict.keys())[0]        # Select first pollutant\n",
    "TEST_HORIZON_LABEL = list(experiments_dict.keys())[2]   # Select third horizon\n",
    "H = experiments_dict[TEST_HORIZON_LABEL]['horizon']\n",
    "WINDOWS = 5                                             # Reduced for computational efficiency\n",
    "STEP_SIZE = experiments_dict[TEST_HORIZON_LABEL]['step_size']\n",
    "\n",
    "refit_comparison = []\n",
    "\n",
    "# =========================================================\n",
    "# Comparative Loop: refit=True vs refit=False\n",
    "# =========================================================\n",
    "for refit_mode in [True, False]:\n",
    "\n",
    "    print(f\"\\nTesting configuration with refit={refit_mode}...\")\n",
    "    \n",
    "    # Simplified model configuration for sensitivity analysis\n",
    "    model = NHITS(\n",
    "        h=H,\n",
    "        input_size=14 * 8,\n",
    "        max_steps=300,\n",
    "        random_seed=SEED,\n",
    "        loss=MAE()\n",
    "    )\n",
    "    \n",
    "    nf = NeuralForecast(models=[model], freq=FREQ)\n",
    "\n",
    "    df_test = pollutants_dict[TEST_POLLUTANT]['df'].copy()\n",
    "\n",
    "    # Deterministic scaling for numerical stability (consistent with main experiment)\n",
    "    df_test['y'] = df_test['y'] * 1e8\n",
    "\n",
    "    # Time tracking\n",
    "    start_t = time.time()\n",
    "    \n",
    "    cv_results = nf.cross_validation(\n",
    "        df=df_test,\n",
    "        h=H,\n",
    "        n_windows=WINDOWS,\n",
    "        step_size=STEP_SIZE,\n",
    "        refit=refit_mode\n",
    "    )\n",
    "\n",
    "    # Rescale forecasts back to physical units\n",
    "    cv_results['y'] = cv_results['y'] * 1e-8\n",
    "    cv_results['NHITS'] = cv_results['NHITS'] * 1e-8\n",
    "    \n",
    "    end_t = time.time()\n",
    "    duration = end_t - start_t\n",
    "    \n",
    "    # Compute global mean absolute error across CV windows\n",
    "    mae_val = np.mean(np.abs(cv_results['y'] - cv_results['NHITS']))\n",
    "    \n",
    "    refit_comparison.append({\n",
    "        'refit': refit_mode,\n",
    "        'MAE': mae_val,\n",
    "        'Time_Sec': duration,\n",
    "        'Time_Per_Window': duration / WINDOWS\n",
    "    })\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Results Analysis\n",
    "# =========================================================\n",
    "comparison_df = pd.DataFrame(refit_comparison)\n",
    "\n",
    "# Percentage change in MAE between configurations\n",
    "comparison_df['MAE_Diff_Pct'] = comparison_df['MAE'].pct_change() * 100\n",
    "\n",
    "# Relative speed-up factor\n",
    "comparison_df['Speedup_Factor'] = (\n",
    "    comparison_df.iloc[0]['Time_Sec'] / comparison_df['Time_Sec']\n",
    ")\n",
    "\n",
    "print(\"\\n=== REFIT TRUE vs FALSE COMPARISON ===\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Logical consistency check\n",
    "mae_diff = abs(\n",
    "    comparison_df.iloc[0]['MAE'] - comparison_df.iloc[1]['MAE']\n",
    ")\n",
    "\n",
    "print(f\"\\nAbsolute MAE difference: {mae_diff:.6f}\")\n",
    "\n",
    "if mae_diff < 0.01:  # Threshold should be interpreted relative to scale\n",
    "    print(\"Conclusion: The error difference is negligible. refit=False is acceptable.\")\n",
    "else:\n",
    "    print(\"Warning: A noticeable error difference was detected. Verify stability assumptions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9baab847",
   "metadata": {},
   "source": [
    "### Input Size Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e9e547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "# DIEBOLD-MARIANO TEST (robust for multiple horizons) Just for Ablation\n",
    "# =================================================================================\n",
    "\n",
    "def diebold_mariano_test(e1, e2, h=1, power=1):\n",
    "    \"\"\"\n",
    "    e1, e2: forecast error arrays (y - y_hat)\n",
    "    h: forecast horizon\n",
    "    power: 1 = MAE, 2 = MSE\n",
    "    \"\"\"\n",
    "\n",
    "    d = np.abs(e1)**power - np.abs(e2)**power\n",
    "    mean_d = np.mean(d)\n",
    "    T = len(d)\n",
    "\n",
    "    # HAC variance (simplified Newey-West style)\n",
    "    gamma = []\n",
    "    for lag in range(1, min(h, T)):\n",
    "        cov = np.cov(d[:-lag], d[lag:])[0, 1]\n",
    "        gamma.append(cov)\n",
    "\n",
    "    var_d = np.var(d) + 2 * np.sum(gamma)\n",
    "\n",
    "    dm_stat = mean_d / np.sqrt(var_d / T)\n",
    "    p_value = 2 * (1 - stats.norm.cdf(np.abs(dm_stat)))\n",
    "\n",
    "    return dm_stat, p_value\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# CONFIGURATIONS\n",
    "# =====================================================\n",
    "\n",
    "INPUT_SIZES = {\n",
    "    \"7d\": 7 * 8,\n",
    "    \"14d\": 14 * 8,\n",
    "    \"21d\": 21 * 8\n",
    "}\n",
    "\n",
    "HORIZONS_TO_TEST = [\"1 days\", \"30 days\"]\n",
    "\n",
    "MODELS = {\n",
    "    \"GRU\": GRU,\n",
    "    \"LSTM\": LSTM,\n",
    "    \"NBEATS\": NBEATS,\n",
    "    \"NHITS\": NHITS,\n",
    "    \"Informer\": Informer,\n",
    "}\n",
    "\n",
    "all_predictions = []\n",
    "\n",
    "# =====================================================\n",
    "# MAIN LOOP ‚Äî GENERATE FORECASTS\n",
    "# =====================================================\n",
    "\n",
    "for pollutant_name, pollutant_ in pollutants_dict.items():\n",
    "\n",
    "    if pollutant_name != 'pm10':\n",
    "        continue\n",
    "\n",
    "    for horizon_label, experiment_ in experiments_dict.items():\n",
    "\n",
    "        if horizon_label not in HORIZONS_TO_TEST:\n",
    "            continue\n",
    "\n",
    "        for model_name, ModelClass in MODELS.items():\n",
    "\n",
    "            for input_label, input_size in INPUT_SIZES.items():\n",
    "\n",
    "                print(f\"{model_name} | {horizon_label} | {input_label}\")\n",
    "\n",
    "                model = ModelClass(\n",
    "                    h=experiment_['horizon'],\n",
    "                    input_size=input_size,\n",
    "                    max_steps=200,\n",
    "                    learning_rate=1e-3,\n",
    "                    batch_size=32,\n",
    "                    windows_batch_size=512,\n",
    "                    random_seed=SEED,\n",
    "                    alias=model_name,\n",
    "                    logger=False,\n",
    "                    loss=MAE(),\n",
    "                )\n",
    "\n",
    "                nf = NeuralForecast(models=[model], freq=FREQ)\n",
    "\n",
    "                df_ = pollutant_['df'].copy()\n",
    "                df_.y = df_.y * pollutant_['scaler']\n",
    "\n",
    "                results_nf = nf.cross_validation(\n",
    "                    df=df_,\n",
    "                    h=experiment_['horizon'],\n",
    "                    n_windows=experiment_['windows'],\n",
    "                    step_size=experiment_['step_size'],\n",
    "                    refit=False,\n",
    "                )\n",
    "\n",
    "                # scale back\n",
    "                scale = pollutant_['scaler']\n",
    "                results_nf['y'] /= scale\n",
    "                results_nf[model_name] /= scale\n",
    "\n",
    "                results_nf['model'] = model_name\n",
    "                results_nf['input_label'] = input_label\n",
    "                results_nf['horizon'] = horizon_label\n",
    "\n",
    "                all_predictions.append(results_nf)\n",
    "\n",
    "# Consolidate all forecasts\n",
    "pred_df = pd.concat(all_predictions).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# DIEBOLD-MARIANO BETWEEN INPUT_SIZES\n",
    "# =====================================================\n",
    "\n",
    "dm_results = []\n",
    "\n",
    "for model_name in MODELS.keys():\n",
    "\n",
    "    for horizon_label in HORIZONS_TO_TEST:\n",
    "\n",
    "        subset = pred_df[\n",
    "            (pred_df['model'] == model_name) &\n",
    "            (pred_df['horizon'] == horizon_label)\n",
    "        ]\n",
    "\n",
    "        horizon_value = experiments_dict[horizon_label]['horizon']\n",
    "\n",
    "        input_labels = list(INPUT_SIZES.keys())\n",
    "\n",
    "        for i in range(len(input_labels)):\n",
    "            for j in range(i + 1, len(input_labels)):\n",
    "\n",
    "                input_a = input_labels[i]\n",
    "                input_b = input_labels[j]\n",
    "\n",
    "                df_a = subset[subset['input_label'] == input_a]\n",
    "                df_b = subset[subset['input_label'] == input_b]\n",
    "\n",
    "                e1 = df_a['y'].values - df_a[model_name].values\n",
    "                e2 = df_b['y'].values - df_b[model_name].values\n",
    "\n",
    "                dm_stat, p_value = diebold_mariano_test(\n",
    "                    e1, e2,\n",
    "                    h=horizon_value,\n",
    "                    power=1\n",
    "                )\n",
    "\n",
    "                dm_results.append({\n",
    "                    \"model\": model_name,\n",
    "                    \"horizon\": horizon_label,\n",
    "                    \"input_a\": input_a,\n",
    "                    \"input_b\": input_b,\n",
    "                    \"dm_stat\": dm_stat,\n",
    "                    \"p_value\": p_value\n",
    "                })\n",
    "\n",
    "dm_df = pd.DataFrame(dm_results)\n",
    "\n",
    "print(\"\\nDiebold-Mariano between input_sizes:\")\n",
    "display(dm_df.sort_values([\"model\", \"horizon\", \"input_a\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a017f4ac",
   "metadata": {},
   "source": [
    "### Epochs Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce977bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "# =====================================================\n",
    "# DATA CONFIGURATION\n",
    "# =====================================================\n",
    "\n",
    "pollutant_name = list(pollutants_dict.keys())[0]\n",
    "pollutant_ = pollutants_dict[pollutant_name]\n",
    "\n",
    "horizon = 56\n",
    "input_size = 56\n",
    "FREQ = \"3H\"\n",
    "SEED = 42\n",
    "\n",
    "df_ = pollutant_[\"df\"].copy()\n",
    "df_.y = df_.y * pollutant_[\"scaler\"]\n",
    "\n",
    "cutoff = df_[\"ds\"].max() - pd.Timedelta(days=30)\n",
    "train_df = df_[df_[\"ds\"] <= cutoff]\n",
    "\n",
    "# =====================================================\n",
    "# MODEL DEFINITIONS\n",
    "# =====================================================\n",
    "\n",
    "model_configs = [\n",
    "    (Informer, \"Informer\"),\n",
    "    (GRU, \"GRU\"),\n",
    "    (LSTM, \"LSTM\"),\n",
    "    (NHITS, \"NHITS\"),\n",
    "    (NBEATS, \"NBEATS\"),\n",
    "]\n",
    "\n",
    "log_dir = Path(\"results\") / \"rq1\" / \"logs_science\"\n",
    "log_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "models = []\n",
    "\n",
    "for model_class, name in model_configs:\n",
    "\n",
    "    logger = CSVLogger(str(log_dir), name=name)\n",
    "\n",
    "    model = model_class(\n",
    "        h=horizon,\n",
    "        input_size=input_size,\n",
    "        max_steps=1500,\n",
    "        learning_rate=1e-3,\n",
    "        batch_size=32,\n",
    "        windows_batch_size=1024,\n",
    "        random_seed=SEED,\n",
    "        alias=name,\n",
    "        loss=MAE(),\n",
    "        logger=logger,\n",
    "    )\n",
    "\n",
    "    models.append(model)\n",
    "\n",
    "# =====================================================\n",
    "# TRAINING\n",
    "# =====================================================\n",
    "\n",
    "nf = NeuralForecast(models=models, freq=FREQ)\n",
    "nf.fit(df=train_df, val_size=horizon)\n",
    "\n",
    "print(\"Training of all models completed.\")\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# LOAD METRICS\n",
    "# =====================================================\n",
    "\n",
    "def get_latest_metrics(model_alias):\n",
    "    model_log_path = log_dir / model_alias\n",
    "    versions = sorted(\n",
    "        glob.glob(str(model_log_path / \"version_*\")),\n",
    "        key=os.path.getmtime\n",
    "    )\n",
    "    if not versions:\n",
    "        return None\n",
    "\n",
    "    csv_path = Path(versions[-1]) / \"metrics.csv\"\n",
    "    return pd.read_csv(csv_path).groupby(\"step\").mean().reset_index()\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# PLOT LEARNING CURVES\n",
    "# =====================================================\n",
    "\n",
    "colors = {\n",
    "    \"NHITS\": \"#104266\",\n",
    "    \"NBEATS\": \"#c49962\",\n",
    "    \"Informer\": \"#6db16d\",\n",
    "    \"LSTM\": \"#bb69b7\",\n",
    "    \"GRU\": \"#9c3e3e\",\n",
    "}\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for _, name in model_configs:\n",
    "    metrics = get_latest_metrics(name)\n",
    "\n",
    "    if metrics is not None:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=metrics[\"step\"],\n",
    "                y=metrics[\"train_loss_epoch\"],\n",
    "                mode=\"lines\",\n",
    "                name=name,\n",
    "                line=dict(color=colors[name], width=2),\n",
    "                legendgroup=name,\n",
    "            )\n",
    "        )\n",
    "\n",
    "fig.update_layout(\n",
    "    template=\"simple_white\",\n",
    "    title={\n",
    "        \"text\": f\"Learning Curves Comparison: {pollutant_name.upper()}\",\n",
    "        \"font\": {\"family\": \"Times New Roman\", \"size\": 24},\n",
    "        \"y\": 0.95,\n",
    "        \"x\": 0.5,\n",
    "        \"xanchor\": \"center\",\n",
    "        \"yanchor\": \"top\",\n",
    "    },\n",
    "    xaxis=dict(\n",
    "        title=dict(text=\"Training Steps\", font=dict(family=\"Times New Roman\", size=20)),\n",
    "        tickfont=dict(family=\"Times New Roman\", size=16),\n",
    "        showline=True,\n",
    "        linewidth=1.2,\n",
    "        linecolor=\"black\",\n",
    "        mirror=True,\n",
    "        showgrid=True,\n",
    "        gridcolor=\"rgba(0,0,0,0.12)\",\n",
    "        zeroline=False,\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title=dict(text=\"Mean Absolute Error (MAE)\", font=dict(family=\"Times New Roman\", size=20)),\n",
    "        tickfont=dict(family=\"Times New Roman\", size=16),\n",
    "        showline=True,\n",
    "        linewidth=1.2,\n",
    "        linecolor=\"black\",\n",
    "        mirror=True,\n",
    "        showgrid=True,\n",
    "        gridcolor=\"rgba(0,0,0,0.12)\",\n",
    "        zeroline=False,\n",
    "    ),\n",
    "    legend=dict(\n",
    "        font=dict(family=\"Times New Roman\", size=14),\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"bottom\",\n",
    "        y=1.02,\n",
    "        xanchor=\"center\",\n",
    "        x=0.48,\n",
    "    ),\n",
    "    width=900,\n",
    "    height=600,\n",
    "    plot_bgcolor=\"white\",\n",
    "    paper_bgcolor=\"white\",\n",
    "    margin=dict(l=80, r=40, t=100, b=80),\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# =====================================================\n",
    "# SAVE PUBLICATION-READY FIGURE\n",
    "# =====================================================\n",
    "\n",
    "output_dir = Path(\"results\") / \"rq1\" / \"figures\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "output_path = output_dir / \"learning_curves.pdf\"\n",
    "\n",
    "fig.write_image(\n",
    "    str(output_path),\n",
    "    format=\"pdf\",\n",
    "    width=700,\n",
    "    height=600,\n",
    "    scale=3,\n",
    ")\n",
    "\n",
    "print(f\"Figure saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561c1ad7",
   "metadata": {},
   "source": [
    "### Deep Learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1ff596",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pollutant_name, pollutant_ in pollutants_dict.items():\n",
    "    for horizon_label, experiment_ in experiments_dict.items():\n",
    "        try:\n",
    "            print_gpu_utilization()\n",
    "            clear_output(wait=True)\n",
    "            print(f\"Running NEURAL | {pollutant_name} | {horizon_label}\")\n",
    "\n",
    "            # -------------------------------\n",
    "            # MODELS\n",
    "            # -------------------------------\n",
    "            models = [\n",
    "                GRU(\n",
    "                    h=experiment_['horizon'],\n",
    "                    input_size=14 * 8,\n",
    "                    max_steps=1000,  # Maximum training steps\n",
    "                    learning_rate=1e-3,  # Learning rate\n",
    "                    batch_size=32,\n",
    "                    windows_batch_size=1024,\n",
    "                    random_seed=SEED,\n",
    "                    alias='GRU',  # Alias for identification\n",
    "                    loss=MAE(),  # Loss function\n",
    "                    logger=False,\n",
    "                ),\n",
    "                Informer(\n",
    "                    h=experiment_['horizon'],\n",
    "                    input_size=14 * 8,\n",
    "                    max_steps=1500,  # Maximum training steps\n",
    "                    learning_rate=1e-3,  # Learning rate\n",
    "                    batch_size=32,\n",
    "                    windows_batch_size=1024,\n",
    "                    random_seed=SEED,\n",
    "                    alias='Informer',\n",
    "                    loss=MAE(),\n",
    "                    logger=False,\n",
    "                ),\n",
    "                LSTM(\n",
    "                    h=experiment_['horizon'],\n",
    "                    input_size=14 * 8,\n",
    "                    max_steps=1000,  # Maximum training steps\n",
    "                    learning_rate=1e-3,  # Learning rate\n",
    "                    batch_size=32,\n",
    "                    windows_batch_size=1024,\n",
    "                    random_seed=SEED,\n",
    "                    alias='LSTM',\n",
    "                    loss=MAE(),\n",
    "                    logger=False,\n",
    "                ),\n",
    "            ]\n",
    "\n",
    "            nf = NeuralForecast(models=models, freq=FREQ)\n",
    "\n",
    "            # -------------------------------\n",
    "            # DATA\n",
    "            # -------------------------------\n",
    "            df_ = pollutant_['df'].copy()\n",
    "            df_.y = df_.y * pollutant_['scaler']\n",
    "\n",
    "            start_time = time.time()\n",
    "            results_nf = nf.cross_validation(\n",
    "                df=df_,\n",
    "                h=experiment_['horizon'],\n",
    "                n_windows=experiment_['windows'],\n",
    "                step_size=experiment_['step_size'],\n",
    "                refit=False,\n",
    "            )\n",
    "            end_time = time.time()\n",
    "\n",
    "            total_time = end_time - start_time\n",
    "            time_per_window = total_time / experiment_['windows']\n",
    "            results_nf['fit_time_seconds'] = total_time\n",
    "\n",
    "            # -------------------------------\n",
    "            # SCALE BACK\n",
    "            # -------------------------------\n",
    "            scale = pollutant_['scaler']\n",
    "            for col in ['y', 'GRU', 'Informer', 'LSTM']:\n",
    "                results_nf[col] = results_nf[col] / scale\n",
    "\n",
    "            # -------------------------------\n",
    "            # SAVE\n",
    "            # -------------------------------\n",
    "            save_results(\n",
    "                results_nf,\n",
    "                model_family=\"dl\",\n",
    "                pollutant=pollutant_name,\n",
    "                horizon_label=horizon_label.replace(\" \", \"\")\n",
    "            )\n",
    "\n",
    "            del nf\n",
    "            del models\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed on {pollutant_name} {horizon_label}: {e}\")\n",
    "            continue  # Move to next instead of crashing the whole notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b27247",
   "metadata": {},
   "source": [
    "### Neural Forecasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644895ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pollutant_name, pollutant_ in pollutants_dict.items():\n",
    "    for horizon_label, experiment_ in experiments_dict.items():\n",
    "        try:\n",
    "            print_gpu_utilization()\n",
    "            clear_output(wait=True)\n",
    "            print(f\"Running NEURAL | {pollutant_name} | {horizon_label}\")\n",
    "\n",
    "            # -------------------------------\n",
    "            # MODELS\n",
    "            # -------------------------------\n",
    "            models = [\n",
    "                NBEATS(\n",
    "                    h=experiment_['horizon'],\n",
    "                    input_size=14*8,\n",
    "                    stack_types=[\"identity\", \"trend\", \"seasonality\"],\n",
    "                    n_blocks=[1, 1, 1],\n",
    "                    mlp_units=3 * [[256, 256]],\n",
    "                    basis='polynomial',\n",
    "                    n_basis=2,\n",
    "                    n_harmonics=2,\n",
    "                    shared_weights=True,\n",
    "                    activation='ReLU',\n",
    "                    max_steps=1000,\n",
    "                    learning_rate=1e-3,\n",
    "                    batch_size=32,\n",
    "                    windows_batch_size=1024,\n",
    "                    random_seed=SEED,\n",
    "                    alias='NBEATS-I',\n",
    "                    loss=MAE(),\n",
    "                ),\n",
    "                NBEATS(\n",
    "                    h=experiment_['horizon'],\n",
    "                    input_size=14*8,\n",
    "                    stack_types=['identity'] * 3,\n",
    "                    n_blocks=[2, 2, 2],\n",
    "                    mlp_units=3 * [[256, 256]],\n",
    "                    shared_weights=False,\n",
    "                    activation='ReLU',\n",
    "                    max_steps=1000,\n",
    "                    learning_rate=1e-3,\n",
    "                    batch_size=32,\n",
    "                    windows_batch_size=1024,\n",
    "                    random_seed=SEED,\n",
    "                    alias='NBEATS-G',\n",
    "                    logger=False,\n",
    "                    loss=MAE(),\n",
    "                ),\n",
    "                NHITS(\n",
    "                    h=experiment_['horizon'],\n",
    "                    input_size=14*8,\n",
    "                    n_blocks=[1, 1, 1],\n",
    "                    mlp_units=3 * [[256, 256]],\n",
    "                    n_pool_kernel_size=[2, 2, 1],\n",
    "                    n_freq_downsample=[4, 2, 1],\n",
    "                    activation='ReLU',\n",
    "                    dropout_prob_theta=0.1,\n",
    "                    max_steps=1000,\n",
    "                    learning_rate=1e-3,\n",
    "                    batch_size=32,\n",
    "                    windows_batch_size=1024,\n",
    "                    random_seed=SEED,\n",
    "                    alias='NHITS',\n",
    "                    logger=False,\n",
    "                    loss=MAE(),\n",
    "                ),\n",
    "            ]\n",
    "\n",
    "            nf = NeuralForecast(models=models, freq=FREQ)\n",
    "\n",
    "            # -------------------------------\n",
    "            # DATA\n",
    "            # -------------------------------\n",
    "            df_ = pollutant_['df'].copy()\n",
    "            df_.y = df_.y * pollutant_['scaler']\n",
    "\n",
    "            start_time = time.time()\n",
    "            results_nf = nf.cross_validation(\n",
    "                df=df_,\n",
    "                h=experiment_['horizon'],\n",
    "                n_windows=experiment_['windows'],\n",
    "                step_size=experiment_['step_size'],\n",
    "                refit=False,\n",
    "            )\n",
    "            end_time = time.time()\n",
    "            \n",
    "            total_time = end_time - start_time\n",
    "            time_per_window = total_time / experiment_['windows']\n",
    "            results_nf['fit_time_seconds'] = total_time\n",
    "\n",
    "            # -------------------------------\n",
    "            # SCALE BACK\n",
    "            # -------------------------------\n",
    "            scale = pollutant_['scaler']\n",
    "            for col in ['y', 'NHITS', 'NBEATS-G', 'NBEATS-I']:\n",
    "                results_nf[col] = results_nf[col] / scale\n",
    "\n",
    "            # -------------------------------\n",
    "            # SAVE\n",
    "            # -------------------------------\n",
    "            save_results(\n",
    "                results_nf,\n",
    "                model_family=\"neural\",\n",
    "                pollutant=pollutant_name,\n",
    "                horizon_label=horizon_label.replace(\" \", \"\")\n",
    "            )\n",
    "\n",
    "            del nf\n",
    "            del models\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Failed on {pollutant_name} {horizon_label}: {e}\")\n",
    "            continue  # Move to next instead of crashing the whole notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88ad9e6",
   "metadata": {},
   "source": [
    "### Statistical Forecasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d7dd23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running STATS | go3 | 1 days\n",
      "Running STATS | go3 | 7 days\n",
      "Running STATS | go3 | 14 days\n",
      "Running STATS | go3 | 30 days\n",
      "Running STATS | no2 | 1 days\n",
      "Running STATS | no2 | 7 days\n",
      "Running STATS | no2 | 14 days\n",
      "Running STATS | no2 | 30 days\n",
      "Running STATS | pm10 | 1 days\n",
      "Running STATS | pm10 | 7 days\n",
      "Running STATS | pm10 | 14 days\n",
      "Running STATS | pm10 | 30 days\n",
      "Running STATS | pm2p5 | 1 days\n",
      "Running STATS | pm2p5 | 7 days\n",
      "Running STATS | pm2p5 | 14 days\n",
      "Running STATS | pm2p5 | 30 days\n"
     ]
    }
   ],
   "source": [
    "for pollutant_name, pollutant_ in pollutants_dict.items():\n",
    "    for horizon_label, experiment_ in experiments_dict.items():\n",
    "\n",
    "        print(f\"Running STATS | {pollutant_name} | {horizon_label}\")\n",
    "\n",
    "        # -------------------------------\n",
    "        # MODELS\n",
    "        # -------------------------------\n",
    "        stat_models = [\n",
    "            AutoARIMA(season_length=SEASON_LENGTH, alias='Arima'),\n",
    "            AutoETS(season_length=SEASON_LENGTH, alias='ETS'),\n",
    "            AutoTheta(season_length=SEASON_LENGTH, alias='Theta'),\n",
    "            SeasonalNaive(season_length=SEASON_LENGTH, alias='SeasonalNaive-8'),\n",
    "            SeasonalNaive(season_length=56, alias='SeasonalNaive-56'),\n",
    "            Naive(alias='Naive'),\n",
    "        ]\n",
    "\n",
    "        sf = StatsForecast(\n",
    "            models=stat_models,\n",
    "            freq=FREQ,\n",
    "            n_jobs=1,\n",
    "        )\n",
    "\n",
    "        # -------------------------------\n",
    "        # DATA\n",
    "        # -------------------------------\n",
    "        df_ = pollutant_['df'].copy()\n",
    "\n",
    "        # -------------------------------\n",
    "        # CROSS-VALIDATION\n",
    "        # -------------------------------\n",
    "        start_time = time.time()\n",
    "        results_sf = sf.cross_validation(\n",
    "            df=df_,\n",
    "            h=experiment_['horizon'],\n",
    "            n_windows=experiment_['windows'],\n",
    "            step_size=experiment_['step_size'],\n",
    "            input_size=14*8,\n",
    "            refit=False,\n",
    "        )\n",
    "        end_time = time.time()\n",
    "        \n",
    "        total_time = end_time - start_time\n",
    "        time_per_window = total_time / experiment_['windows']\n",
    "        results_sf['fit_time_seconds'] = total_time\n",
    "        \n",
    "        # -------------------------------\n",
    "        # SAVE\n",
    "        # -------------------------------\n",
    "        save_results(\n",
    "            results_sf,\n",
    "            model_family=\"stats\",\n",
    "            pollutant=pollutant_name,\n",
    "            horizon_label=horizon_label.replace(\" \", \"\")\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8834ae7",
   "metadata": {},
   "source": [
    "### Machine Learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c3b1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pollutant_name, pollutant_ in pollutants_dict.items():\n",
    "\n",
    "    if pollutant_name == 'go3' or pollutant_name == 'pm10' or pollutant_name == 'no2':\n",
    "        continue\n",
    "\n",
    "    for horizon_label, experiment_ in experiments_dict.items():\n",
    "\n",
    "        try:\n",
    "            clear_output(wait=True)\n",
    "            print(f\"Running ML | {pollutant_name} | {horizon_label}\")\n",
    "\n",
    "            # -------------------------------\n",
    "            # MODEL \n",
    "            # -------------------------------\n",
    "            lgb_model = lgb.LGBMRegressor(\n",
    "                n_estimators=500,\n",
    "                learning_rate=0.05,\n",
    "                num_leaves=31,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                random_state=SEED,\n",
    "                n_jobs=1,\n",
    "            )\n",
    "            rf_model = RandomForestRegressor(\n",
    "                n_estimators=500,\n",
    "                max_depth=10,\n",
    "                random_state=SEED,\n",
    "                n_jobs=1,\n",
    "            )\n",
    "            xgb_model = xgb.XGBRegressor(\n",
    "                n_estimators=500,\n",
    "                learning_rate=0.05,\n",
    "                max_depth=6,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                random_state=SEED,\n",
    "                n_jobs=1,\n",
    "            )\n",
    "\n",
    "            # -------------------------------\n",
    "            # MLForecast (lags + calendar)\n",
    "            # -------------------------------\n",
    "            mlf = MLForecast(\n",
    "                models={\n",
    "                    'RandomForest': rf_model,\n",
    "                    'XGBoost': xgb_model,\n",
    "                    'LightGBM': lgb_model,\n",
    "                },\n",
    "                freq=FREQ,\n",
    "                lags=[1, 2, 4, 8, 16, 24, 56, 112],\n",
    "                lag_transforms={\n",
    "                    8:  [RollingMean(window_size=8), ExpandingMean()],\n",
    "                    56: [RollingMean(window_size=56)],\n",
    "                },\n",
    "                date_features=[\n",
    "                    'hour',       \n",
    "                    'dayofweek',  \n",
    "                    'month',      \n",
    "                    'dayofyear',  \n",
    "                ],\n",
    "            )\n",
    "\n",
    "            # -------------------------------\n",
    "            # DATA\n",
    "            # -------------------------------\n",
    "            df_ = pollutant_['df'].copy()\n",
    "            df_ = df_.sort_values(['unique_id', 'ds'])\n",
    "\n",
    "            # (opcional, mas recomendado) garantir dtype datetime\n",
    "            df_['ds'] = pd.to_datetime(df_['ds'])\n",
    "\n",
    "            # -------------------------------\n",
    "            # CROSS-VALIDATION\n",
    "            # -------------------------------\n",
    "            start_time = time.time()\n",
    "            results_ml = mlf.cross_validation(\n",
    "                df=df_,\n",
    "                h=experiment_['horizon'],\n",
    "                n_windows=experiment_['windows'],\n",
    "                step_size=experiment_['step_size'],\n",
    "                refit=False,\n",
    "            )\n",
    "            end_time = time.time()\n",
    "\n",
    "            total_time = end_time - start_time\n",
    "            results_ml['fit_time_seconds'] = total_time\n",
    "\n",
    "            # -------------------------------\n",
    "            # SAVE\n",
    "            # -------------------------------\n",
    "            save_results(\n",
    "                results_ml,\n",
    "                model_family=\"ml\",\n",
    "                pollutant=pollutant_name,\n",
    "                horizon_label=horizon_label.replace(\" \", \"\")\n",
    "            )\n",
    "\n",
    "            del mlf\n",
    "            del rf_model, xgb_model, lgb_model\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Failed on {pollutant_name} {horizon_label}: {e}\")\n",
    "            continue "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ade47f",
   "metadata": {},
   "source": [
    "## Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea63c421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building FULL | go3 | 1days\n",
      "Building FULL | go3 | 7days\n",
      "Building FULL | go3 | 14days\n",
      "Building FULL | go3 | 30days\n",
      "Building FULL | no2 | 1days\n",
      "Building FULL | no2 | 7days\n",
      "Building FULL | no2 | 14days\n",
      "Building FULL | no2 | 30days\n",
      "Building FULL | pm10 | 1days\n",
      "Building FULL | pm10 | 7days\n",
      "Building FULL | pm10 | 14days\n",
      "Building FULL | pm10 | 30days\n",
      "Building FULL | pm2p5 | 1days\n",
      "Building FULL | pm2p5 | 7days\n",
      "Building FULL | pm2p5 | 14days\n",
      "Building FULL | pm2p5 | 30days\n"
     ]
    }
   ],
   "source": [
    "FULL_DIR = BASE_RESULTS / \"full\"\n",
    "FULL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def build_full_results(pollutant, horizon_label):\n",
    "    \"\"\"\n",
    "    Concatena neural + stats + ml para um (pollutant, horizon)\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "\n",
    "    for family in [\"neural\", \"stats\", \"ml\", \"dl\"]:\n",
    "        fpath = BASE_RESULTS / family / f\"{pollutant}_{horizon_label}.csv\"\n",
    "\n",
    "        if fpath.exists():\n",
    "            df = pd.read_csv(fpath)\n",
    "\n",
    "            if 'fit_time_seconds' in df.columns:\n",
    "                df = df.drop(columns=['fit_time_seconds'])\n",
    "            \n",
    "            dfs.append(df)\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Missing: {fpath}\")\n",
    "\n",
    "    if not dfs:\n",
    "        raise ValueError(\"No result files found.\")\n",
    "\n",
    "    df_full = dfs[0]\n",
    "    for df in dfs[1:]:\n",
    "        df_full = df_full.merge(\n",
    "            df,\n",
    "            on=[\"unique_id\", \"ds\", \"cutoff\", \"y\"],\n",
    "            how=\"inner\"\n",
    "        )\n",
    "\n",
    "    return df_full\n",
    "\n",
    "for pollutant_name in pollutants_dict.keys():\n",
    "    for horizon_label in experiments_dict.keys():\n",
    "\n",
    "        horizon_clean = horizon_label.replace(\" \", \"\")\n",
    "\n",
    "        print(f\"Building FULL | {pollutant_name} | {horizon_clean}\")\n",
    "\n",
    "        df_full = build_full_results(\n",
    "            pollutant=pollutant_name,\n",
    "            horizon_label=horizon_clean\n",
    "        )\n",
    "\n",
    "        df_full.to_csv(\n",
    "            FULL_DIR / f\"{pollutant_name}_{horizon_clean}.csv\",\n",
    "            index=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd21fc2",
   "metadata": {},
   "source": [
    "## **Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46893ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating | go3 | 14days\n",
      "Evaluating | go3 | 1days\n",
      "Evaluating | go3 | 30days\n",
      "Evaluating | go3 | 7days\n",
      "Evaluating | no2 | 14days\n",
      "Evaluating | no2 | 1days\n",
      "Evaluating | no2 | 30days\n",
      "Evaluating | no2 | 7days\n",
      "Evaluating | pm10 | 14days\n",
      "Evaluating | pm10 | 1days\n",
      "Evaluating | pm10 | 30days\n",
      "Evaluating | pm10 | 7days\n",
      "Evaluating | pm2p5 | 14days\n",
      "Evaluating | pm2p5 | 1days\n",
      "Evaluating | pm2p5 | 30days\n",
      "Evaluating | pm2p5 | 7days\n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# METRICS\n",
    "# ==================================================\n",
    "\n",
    "def mae(y, yhat):\n",
    "    return np.mean(np.abs(y - yhat))\n",
    "\n",
    "\n",
    "def mse(y, yhat):\n",
    "    return np.mean((y - yhat) ** 2)\n",
    "\n",
    "\n",
    "def rmse(y, yhat):\n",
    "    return np.sqrt(mse(y, yhat))\n",
    "\n",
    "\n",
    "def smape(y, yhat):\n",
    "    denom = (np.abs(y) + np.abs(yhat)) / 2\n",
    "    mask = denom != 0\n",
    "    if mask.sum() == 0:\n",
    "        return np.nan\n",
    "    return np.mean(np.abs(y[mask] - yhat[mask]) / denom[mask])\n",
    "\n",
    "\n",
    "def mae_conditional(y, yhat, threshold):\n",
    "    mask = y >= threshold\n",
    "    if mask.sum() == 0:\n",
    "        return np.nan\n",
    "    return np.mean(np.abs(y[mask] - yhat[mask]))\n",
    "\n",
    "\n",
    "def bias_conditional(y, yhat, threshold):\n",
    "    mask = y >= threshold\n",
    "    if mask.sum() == 0:\n",
    "        return np.nan\n",
    "    return np.mean(yhat[mask] - y[mask])\n",
    "\n",
    "\n",
    "def skill_score(model_err, baseline_err):\n",
    "    if baseline_err == 0 or np.isnan(baseline_err):\n",
    "        return np.nan\n",
    "    return 1 - model_err / baseline_err\n",
    "\n",
    "\n",
    "def extreme_event_metrics(y, yhat, threshold):\n",
    "    y_event = y >= threshold\n",
    "    yhat_event = yhat >= threshold\n",
    "\n",
    "    tp = np.sum(y_event & yhat_event)\n",
    "    fp = np.sum(~y_event & yhat_event)\n",
    "    fn = np.sum(y_event & ~yhat_event)\n",
    "\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else np.nan\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else np.nan\n",
    "\n",
    "    if precision > 0 and recall > 0:\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "    else:\n",
    "        f1 = np.nan\n",
    "\n",
    "    return precision, recall, f1\n",
    "\n",
    "\n",
    "# ==================================================\n",
    "# EVALUATION LOOP (ROBUST & NO LEAKAGE)\n",
    "# ==================================================\n",
    "\n",
    "BASE = Path(\"Results/RQ1/full\")\n",
    "baseline_name = \"Naive\"\n",
    "\n",
    "STEPS_PER_YEAR = 365 * 8  # dados 3h\n",
    "WINDOW_P95 = STEPS_PER_YEAR\n",
    "\n",
    "records = []\n",
    "\n",
    "for file in BASE.glob(\"*.csv\"):\n",
    "\n",
    "    pollutant, horizon = file.stem.split(\"_\", 1)\n",
    "    print(f\"Evaluating | {pollutant} | {horizon}\")\n",
    "\n",
    "    # --------------------------------------\n",
    "    # LOAD PREDICTIONS\n",
    "    # --------------------------------------\n",
    "    df_pred = pd.read_csv(file)\n",
    "    df_pred['ds'] = pd.to_datetime(df_pred['ds'])\n",
    "    df_pred['cutoff'] = pd.to_datetime(df_pred['cutoff'])\n",
    "\n",
    "    # --------------------------------------\n",
    "    # LOAD FULL GROUND TRUTH\n",
    "    # --------------------------------------\n",
    "    df_true = pollutants_dict[pollutant]['df'].copy()\n",
    "    df_true['ds'] = pd.to_datetime(df_true['ds'])\n",
    "\n",
    "    # --------------------------------------\n",
    "    # DEFINE MODEL COLUMNS (CLEAN)\n",
    "    # --------------------------------------\n",
    "    model_cols = [\n",
    "        c for c in df_pred.columns\n",
    "        if (\n",
    "            c not in [\"unique_id\", \"ds\", \"cutoff\", \"y\"]\n",
    "            and not c.startswith(\"fit_time\")\n",
    "            and df_pred[c].dtype in [np.float64, np.float32]\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    if baseline_name not in model_cols:\n",
    "        raise ValueError(f\"Baseline '{baseline_name}' not found.\")\n",
    "\n",
    "    # --------------------------------------\n",
    "    # GROUP BY FOLD\n",
    "    # --------------------------------------\n",
    "    for (uid, cutoff), df_fold in df_pred.groupby([\"unique_id\", \"cutoff\"]):\n",
    "\n",
    "        # ----------------------------------\n",
    "        # TRAIN WINDOW (NO LEAKAGE)\n",
    "        # ----------------------------------\n",
    "        y_train_full = (\n",
    "            df_true\n",
    "            .query(\"unique_id == @uid and ds <= @cutoff\")\n",
    "            ['y']\n",
    "            .values\n",
    "        )\n",
    "\n",
    "        if len(y_train_full) < WINDOW_P95:\n",
    "            continue\n",
    "\n",
    "        y_train_recent = y_train_full[-WINDOW_P95:]\n",
    "        p95 = np.percentile(y_train_recent, 95)\n",
    "\n",
    "        # ----------------------------------\n",
    "        # TEST HORIZON\n",
    "        # ----------------------------------\n",
    "        y_full = df_fold['y'].values\n",
    "        y_base_full = df_fold[baseline_name].values\n",
    "\n",
    "        # baseline v√°lido\n",
    "        mask_base_valid = ~np.isnan(y_base_full)\n",
    "\n",
    "        if mask_base_valid.sum() == 0:\n",
    "            continue\n",
    "\n",
    "        # ----------------------------------\n",
    "        # EVALUATE EACH MODEL\n",
    "        # ----------------------------------\n",
    "        for model in model_cols:\n",
    "\n",
    "            yhat_full = df_fold[model].values\n",
    "            mask_valid = ~np.isnan(yhat_full)\n",
    "\n",
    "            if mask_valid.sum() == 0:\n",
    "                continue\n",
    "\n",
    "            y_valid = y_full[mask_valid]\n",
    "            yhat = yhat_full[mask_valid]\n",
    "            y_base_valid = y_base_full[mask_valid]\n",
    "\n",
    "            # m√©tricas gerais do modelo\n",
    "            mae_model = mae(y_valid, yhat)\n",
    "            rmse_model = rmse(y_valid, yhat)\n",
    "            smape_model = smape(y_valid, yhat)\n",
    "\n",
    "            # m√©tricas do baseline (ajustadas ao mesmo subconjunto)\n",
    "            mae_base_model = mae(y_valid, y_base_valid)\n",
    "            rmse_base_model = rmse(y_valid, y_base_valid)\n",
    "            smape_base_model = smape(y_valid, y_base_valid)\n",
    "            mae_base_model_p95 = mae_conditional(y_valid, y_base_valid, p95)\n",
    "\n",
    "            # Skill Scores gerais\n",
    "            skill_mae = skill_score(mae_model, mae_base_model)\n",
    "            skill_rmse = skill_score(rmse_model, rmse_base_model)\n",
    "            skill_smape = skill_score(smape_model, smape_base_model)\n",
    "\n",
    "            # extremos\n",
    "            mae_p95 = mae_conditional(y_valid, yhat, p95)\n",
    "            skill_p95 = skill_score(mae_p95, mae_base_model_p95)\n",
    "            bias_p95 = bias_conditional(y_valid, yhat, p95)\n",
    "\n",
    "            precision, recall, f1 = extreme_event_metrics(\n",
    "                y_valid, yhat, p95\n",
    "            )\n",
    "\n",
    "            records.append({\n",
    "                \"pollutant\": pollutant,\n",
    "                \"horizon\": horizon,\n",
    "                \"unique_id\": uid,\n",
    "                \"cutoff\": cutoff,\n",
    "                \"model\": model,\n",
    "\n",
    "                # m√©tricas m√©dias e seus respectivos skill scores\n",
    "                \"MAE\": mae_model,\n",
    "                \"Skill_MAE\": skill_mae,\n",
    "                \"RMSE\": rmse_model,\n",
    "                \"Skill_RMSE\": skill_rmse,\n",
    "                \"sMAPE\": smape_model,\n",
    "                \"Skill_sMAPE\": skill_smape,\n",
    "\n",
    "                # extremos\n",
    "                \"MAE_p95\": mae_p95,\n",
    "                \"Skill_p95\": skill_p95,\n",
    "                \"Bias_p95\": bias_p95,\n",
    "                \"Precision_p95\": precision,\n",
    "                \"Recall_p95\": recall,\n",
    "                \"F1_p95\": f1,\n",
    "            })\n",
    "\n",
    "# ==================================================\n",
    "# FINAL DATAFRAME\n",
    "# ==================================================\n",
    "\n",
    "metrics_df = pd.DataFrame(records)\n",
    "metrics_df.to_csv(r'..\\Masters 26\\Results\\RQ1\\metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "29d0c602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "MAE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RMSE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sMAPE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAE_p95",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Skill_p95",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "F1_p95",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "f16153ec-4b51-4602-a198-ffc58bec08a0",
       "rows": [
        [
         "NHITS",
         "5.482231828045827e-09",
         "7.119523533680956e-09",
         "0.43322012746784194",
         "1.4297694176898879e-08",
         "0.0685996448982497",
         "0.5270307622487007"
        ],
        [
         "NBEATS-G",
         "5.486953435445975e-09",
         "7.120523674975165e-09",
         "0.43329788178402956",
         "1.4282468020249357e-08",
         "0.0888994780076033",
         "0.5231546337499253"
        ],
        [
         "NBEATS-I",
         "5.502031630388856e-09",
         "7.150968275521991e-09",
         "0.4362184058803969",
         "1.4289177323156857e-08",
         "0.09802982713951955",
         "0.5163369704127111"
        ],
        [
         "LightGBM",
         "5.812858236653306e-09",
         "7.385410783014042e-09",
         "0.4360806297940273",
         "1.4217930157087779e-08",
         "0.07778965926031103",
         "0.49877278357698046"
        ],
        [
         "LSTM",
         "5.912126240905075e-09",
         "7.554949531217718e-09",
         "0.4627178518238407",
         "1.4653624219015052e-08",
         "-0.459747509504817",
         "0.5404042375698855"
        ],
        [
         "GRU",
         "5.976189053344934e-09",
         "7.626346261370728e-09",
         "0.46612587120888455",
         "1.4900906536339266e-08",
         "-0.46121479356152706",
         "0.5517130167381075"
        ],
        [
         "Informer",
         "6.4103027972176255e-09",
         "8.244619432786228e-09",
         "0.5423446289880359",
         "1.994524557195257e-08",
         "-0.7888183611871725",
         "0.5567747455486788"
        ],
        [
         "RandomForest",
         "6.692650676851732e-09",
         "8.406920176169692e-09",
         "0.5785076174287758",
         "1.775420842302711e-08",
         "-1.075025398912465",
         "0.6811984495254052"
        ],
        [
         "Theta",
         "7.3180146067672434e-09",
         "8.96657769781638e-09",
         "0.5377940766845007",
         "1.528884399957021e-08",
         "0.053667142734853575",
         "0.5203137421162815"
        ],
        [
         "Arima",
         "7.3479699463809006e-09",
         "9.114442268369437e-09",
         "0.5824363234095347",
         "1.499569974183899e-08",
         "0.08451423612010232",
         "0.5020207040993222"
        ],
        [
         "XGBoost",
         "7.364160197565306e-09",
         "9.250484257252605e-09",
         "0.5937722257159284",
         "2.0925051805899694e-08",
         "-1.297546041348495",
         null
        ],
        [
         "SeasonalNaive-8",
         "7.408532067505299e-09",
         "9.3166092842739e-09",
         "0.5651676914086502",
         "1.469198453319136e-08",
         "-0.3037594007847482",
         "0.4616266253361666"
        ],
        [
         "SeasonalNaive-56",
         "8.085384277591721e-09",
         "1.0308843407473497e-08",
         "0.6020231589156038",
         "1.5594483845134017e-08",
         "-0.8417830056109117",
         "0.3332218446949965"
        ],
        [
         "Naive",
         "8.547524223875713e-09",
         "1.0426401713319414e-08",
         "0.7099058215405823",
         "1.9073638599639283e-08",
         "0.0",
         "0.4480627542476974"
        ],
        [
         "ETS",
         "2.9009161075076806e-05",
         "6.655066860914735e-05",
         "0.6068466304665215",
         "0.00018219572823791142",
         "-39042.22153122314",
         "0.40802129591865277"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 15
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>sMAPE</th>\n",
       "      <th>MAE_p95</th>\n",
       "      <th>Skill_p95</th>\n",
       "      <th>F1_p95</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NHITS</th>\n",
       "      <td>5.482232e-09</td>\n",
       "      <td>7.119524e-09</td>\n",
       "      <td>0.433220</td>\n",
       "      <td>1.429769e-08</td>\n",
       "      <td>0.068600</td>\n",
       "      <td>0.527031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NBEATS-G</th>\n",
       "      <td>5.486953e-09</td>\n",
       "      <td>7.120524e-09</td>\n",
       "      <td>0.433298</td>\n",
       "      <td>1.428247e-08</td>\n",
       "      <td>0.088899</td>\n",
       "      <td>0.523155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NBEATS-I</th>\n",
       "      <td>5.502032e-09</td>\n",
       "      <td>7.150968e-09</td>\n",
       "      <td>0.436218</td>\n",
       "      <td>1.428918e-08</td>\n",
       "      <td>0.098030</td>\n",
       "      <td>0.516337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>5.812858e-09</td>\n",
       "      <td>7.385411e-09</td>\n",
       "      <td>0.436081</td>\n",
       "      <td>1.421793e-08</td>\n",
       "      <td>0.077790</td>\n",
       "      <td>0.498773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM</th>\n",
       "      <td>5.912126e-09</td>\n",
       "      <td>7.554950e-09</td>\n",
       "      <td>0.462718</td>\n",
       "      <td>1.465362e-08</td>\n",
       "      <td>-0.459748</td>\n",
       "      <td>0.540404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRU</th>\n",
       "      <td>5.976189e-09</td>\n",
       "      <td>7.626346e-09</td>\n",
       "      <td>0.466126</td>\n",
       "      <td>1.490091e-08</td>\n",
       "      <td>-0.461215</td>\n",
       "      <td>0.551713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Informer</th>\n",
       "      <td>6.410303e-09</td>\n",
       "      <td>8.244619e-09</td>\n",
       "      <td>0.542345</td>\n",
       "      <td>1.994525e-08</td>\n",
       "      <td>-0.788818</td>\n",
       "      <td>0.556775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>6.692651e-09</td>\n",
       "      <td>8.406920e-09</td>\n",
       "      <td>0.578508</td>\n",
       "      <td>1.775421e-08</td>\n",
       "      <td>-1.075025</td>\n",
       "      <td>0.681198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Theta</th>\n",
       "      <td>7.318015e-09</td>\n",
       "      <td>8.966578e-09</td>\n",
       "      <td>0.537794</td>\n",
       "      <td>1.528884e-08</td>\n",
       "      <td>0.053667</td>\n",
       "      <td>0.520314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arima</th>\n",
       "      <td>7.347970e-09</td>\n",
       "      <td>9.114442e-09</td>\n",
       "      <td>0.582436</td>\n",
       "      <td>1.499570e-08</td>\n",
       "      <td>0.084514</td>\n",
       "      <td>0.502021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>7.364160e-09</td>\n",
       "      <td>9.250484e-09</td>\n",
       "      <td>0.593772</td>\n",
       "      <td>2.092505e-08</td>\n",
       "      <td>-1.297546</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SeasonalNaive-8</th>\n",
       "      <td>7.408532e-09</td>\n",
       "      <td>9.316609e-09</td>\n",
       "      <td>0.565168</td>\n",
       "      <td>1.469198e-08</td>\n",
       "      <td>-0.303759</td>\n",
       "      <td>0.461627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SeasonalNaive-56</th>\n",
       "      <td>8.085384e-09</td>\n",
       "      <td>1.030884e-08</td>\n",
       "      <td>0.602023</td>\n",
       "      <td>1.559448e-08</td>\n",
       "      <td>-0.841783</td>\n",
       "      <td>0.333222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive</th>\n",
       "      <td>8.547524e-09</td>\n",
       "      <td>1.042640e-08</td>\n",
       "      <td>0.709906</td>\n",
       "      <td>1.907364e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.448063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ETS</th>\n",
       "      <td>2.900916e-05</td>\n",
       "      <td>6.655067e-05</td>\n",
       "      <td>0.606847</td>\n",
       "      <td>1.821957e-04</td>\n",
       "      <td>-39042.221531</td>\n",
       "      <td>0.408021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MAE          RMSE     sMAPE       MAE_p95  \\\n",
       "model                                                                  \n",
       "NHITS             5.482232e-09  7.119524e-09  0.433220  1.429769e-08   \n",
       "NBEATS-G          5.486953e-09  7.120524e-09  0.433298  1.428247e-08   \n",
       "NBEATS-I          5.502032e-09  7.150968e-09  0.436218  1.428918e-08   \n",
       "LightGBM          5.812858e-09  7.385411e-09  0.436081  1.421793e-08   \n",
       "LSTM              5.912126e-09  7.554950e-09  0.462718  1.465362e-08   \n",
       "GRU               5.976189e-09  7.626346e-09  0.466126  1.490091e-08   \n",
       "Informer          6.410303e-09  8.244619e-09  0.542345  1.994525e-08   \n",
       "RandomForest      6.692651e-09  8.406920e-09  0.578508  1.775421e-08   \n",
       "Theta             7.318015e-09  8.966578e-09  0.537794  1.528884e-08   \n",
       "Arima             7.347970e-09  9.114442e-09  0.582436  1.499570e-08   \n",
       "XGBoost           7.364160e-09  9.250484e-09  0.593772  2.092505e-08   \n",
       "SeasonalNaive-8   7.408532e-09  9.316609e-09  0.565168  1.469198e-08   \n",
       "SeasonalNaive-56  8.085384e-09  1.030884e-08  0.602023  1.559448e-08   \n",
       "Naive             8.547524e-09  1.042640e-08  0.709906  1.907364e-08   \n",
       "ETS               2.900916e-05  6.655067e-05  0.606847  1.821957e-04   \n",
       "\n",
       "                     Skill_p95    F1_p95  \n",
       "model                                     \n",
       "NHITS                 0.068600  0.527031  \n",
       "NBEATS-G              0.088899  0.523155  \n",
       "NBEATS-I              0.098030  0.516337  \n",
       "LightGBM              0.077790  0.498773  \n",
       "LSTM                 -0.459748  0.540404  \n",
       "GRU                  -0.461215  0.551713  \n",
       "Informer             -0.788818  0.556775  \n",
       "RandomForest         -1.075025  0.681198  \n",
       "Theta                 0.053667  0.520314  \n",
       "Arima                 0.084514  0.502021  \n",
       "XGBoost              -1.297546       NaN  \n",
       "SeasonalNaive-8      -0.303759  0.461627  \n",
       "SeasonalNaive-56     -0.841783  0.333222  \n",
       "Naive                 0.000000  0.448063  \n",
       "ETS              -39042.221531  0.408021  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = (\n",
    "    metrics_df\n",
    "    .groupby([\"model\"])\n",
    "    .agg({\n",
    "        \"MAE\": \"mean\",\n",
    "        \"RMSE\": \"mean\",\n",
    "        \"sMAPE\": \"mean\",\n",
    "        \"MAE_p95\": \"mean\",\n",
    "        \"Skill_p95\": \"mean\",\n",
    "        \"F1_p95\": \"mean\"\n",
    "    })\n",
    "    .sort_values(\"MAE\")\n",
    ")\n",
    "summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
